# Guide d'Int√©gration : AI Firewall avec OpenClaw

Bienvenue ! Ce guide explique √©tape par √©tape comment int√©grer le module **AI Firewall** √† votre application cliente **OpenClaw**. Ce module agit comme un proxy s√©curis√© entre OpenClaw et les fournisseurs d'IA (comme OpenAI ou Anthropic), en ajoutant de l'authentification, des contr√¥les budg√©taires et un streaming transparent.

Ce guide est con√ßu pour √™tre accessible √† tous les niveaux : d√©veloppeurs d√©butants, interm√©diaires ou experts. Nous partons des bases et avan√ßons pas √† pas.

## Table des Mati√®res
1. [Qu'est-ce que AI Firewall ?](#qu-est-ce-que-ai-firewall-)
2. [Pr√©requis](#pr√©requis)
3. [Installation et Configuration](#installation-et-configuration)
4. [Modification d'OpenClaw](#modification-d-openclaw)
5. [Test de l'Int√©gration](#test-de-lint√©gration)
6. [D√©pannage](#d√©pannage)
7. [Fonctionnalit√©s Avanc√©es](#fonctionnalit√©s-avanc√©es)

## 1. Qu'est-ce que AI Firewall ?

AI Firewall est un **proxy reverse** √©crit en Python avec FastAPI. Il :
- **S'interpose** entre votre client (OpenClaw) et le fournisseur d'IA.
- **Authentifie** les requ√™tes avec une cl√© API interne.
- **Contr√¥le le budget** : Limite les d√©penses quotidiennes par utilisateur (ex. 5 $).
- **G√®re le streaming** : Transmet les r√©ponses en temps r√©el (Server-Sent Events) sans ajouter de latence.
- **Compte les tokens** : Calcule automatiquement les co√ªts apr√®s chaque requ√™te (en arri√®re-plan).

**Avantages** :
- S√©curit√© : Prot√®ge vos cl√©s API upstream.
- √âconomie : √âvite les d√©passements budg√©taires.
- Transparence : Les appels API restent identiques, juste l'URL change.

## 2. Pr√©requis

Avant de commencer, assurez-vous d'avoir :
- **Docker** install√© (version 20+ recommand√©e). [Guide d'installation](https://docs.docker.com/get-docker/).
- **Docker Compose** (inclus avec Docker Desktop).
- Un compte chez un fournisseur d'IA (ex. OpenRouter, OpenAI). Vous aurez besoin d'une cl√© API.
- **OpenClaw** : Votre application cliente qui appelle `/v1/chat/completions`.

Si vous n'avez pas Docker, vous pouvez installer Python 3.12+ et Redis localement, mais Docker est plus simple pour la production.

## 3. Installation et Configuration

### √âtape 1 : T√©l√©charger le Projet
Clonez ou t√©l√©chargez ce d√©p√¥t GitHub :
```bash
git clone https://github.com/votre-repo/ai-firewall.git
cd ai-firewall
```

### √âtape 2 : Configurer les Variables d'Environnement
Le module utilise un fichier `.env` pour les configurations sensibles. Ne partagez jamais ce fichier !

1. Copiez le fichier exemple :
   ```bash
   cp .env.example .env
   ```

2. Ouvrez `.env` avec un √©diteur de texte (ex. VS Code) et remplissez :
   - `INTERNAL_API_KEY` : Une cl√© secr√®te pour authentifier OpenClaw (ex. `ma-cle-secrete-123`).
   - `UPSTREAM_BASE_URL` : L'URL de votre fournisseur (ex. `https://openrouter.ai/api` ou `https://api.openai.com`).
   - `UPSTREAM_API_KEY` : Votre cl√© API du fournisseur (ex. `sk-or-v1-xxxxxx`).
   - `DAILY_BUDGET_LIMIT` : Limite budg√©taire par jour (ex. `5.0` pour 5 $).
   - Laissez `REDIS_URL` par d√©faut si vous utilisez Docker.

   Exemple de `.env` :
   ```
   INTERNAL_API_KEY=ma-cle-secrete-123
   UPSTREAM_BASE_URL=https://openrouter.ai/api
   UPSTREAM_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxx
   DAILY_BUDGET_LIMIT=5.0
   ```

### √âtape 3 : Lancer le Proxy
Avec Docker Compose (recommand√©) :
```bash
docker compose up --build -d
```
- Cela construit l'image et lance deux services : `proxy` (port 8000) et `redis` (port 6379).
- Le proxy sera accessible sur `http://localhost:8000`.

Pour v√©rifier : Ouvrez `http://localhost:8000/health` dans un navigateur. Vous devriez voir `{"status": "ok"}`.

## 4. Modification d'OpenClaw

Maintenant, configurez OpenClaw pour utiliser le proxy au lieu de contacter directement le fournisseur.

### Changements N√©cessaires
Dans le code d'OpenClaw (probablement dans un fichier comme `api_client.py` ou similaire) :
1. **Changez l'URL de base** : Remplacez l'URL du fournisseur par `http://localhost:8000` (ou l'IP de votre serveur).
2. **Ajoutez l'authentification** : Incluez le header `Authorization: Bearer <INTERNAL_API_KEY>` dans chaque requ√™te.

### Exemple de Code (Python avec httpx ou requests)
Supposons qu'OpenClaw utilise `requests` pour appeler l'API :

**Avant (direct vers le fournisseur)** :
```python
import requests

response = requests.post(
    "https://openrouter.ai/api/v1/chat/completions",
    headers={
        "Authorization": "Bearer sk-or-v1-xxxxxx",
        "Content-Type": "application/json",
    },
    json={
        "model": "openai/gpt-4o-mini",
        "messages": [{"role": "user", "content": "Bonjour !"}],
        "stream": True,
    },
)
```

**Apr√®s (via AI Firewall)** :
```python
import requests

response = requests.post(
    "http://localhost:8000/v1/chat/completions",  # Nouveau URL !
    headers={
        "Authorization": "Bearer ma-cle-secrete-123",  # Nouvelle cl√© !
        "Content-Type": "application/json",
    },
    json={
        "model": "openai/gpt-4o-mini",
        "messages": [{"role": "user", "content": "Bonjour !"}],
        "stream": True,
    },
)
```

- Le reste du code (parsing de la r√©ponse, gestion du streaming) reste identique !
- Pour le streaming, OpenClaw lira les chunks SSE comme avant.

### Si OpenClaw Utilise un SDK (ex. OpenAI SDK)
Si OpenClaw utilise le SDK officiel d'OpenAI :
```python
from openai import OpenAI

client = OpenAI(
    api_key="ma-cle-secrete-123",  # Cl√© interne
    base_url="http://localhost:8000",  # Proxy URL
)

response = client.chat.completions.create(
    model="openai/gpt-4o-mini",
    messages=[{"role": "user", "content": "Bonjour !"}],
    stream=True,
)
```

- Le SDK g√®re automatiquement les headers.

## 5. Test de l'Int√©gration

### Test Simple (avec curl)
Testez le proxy directement :
```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer ma-cle-secrete-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o-mini",
    "stream": true,
    "messages": [{"role": "user", "content": "Hello, world!"}]
  }'
```
- Vous devriez voir les chunks SSE en streaming (ex. `data: {"choices": [...]}`).
- Si √ßa marche, int√©grez √† OpenClaw.

### Test avec OpenClaw
- Lancez OpenClaw et faites une requ√™te.
- V√©rifiez les logs du proxy : `docker compose logs proxy`.
- Surveillez le budget : `docker compose exec redis redis-cli GET budget:default:2026-02-18` (ajustez la date).

### V√©rifications
- **Auth** : Sans le header `Authorization`, vous obtenez `401 Unauthorized`.
- **Budget** : Apr√®s quelques requ√™tes co√ªteuses, `402 Payment Required`.
- **Streaming** : Les r√©ponses arrivent en temps r√©el.

## 6. D√©pannage

### Probl√®me : "Connection refused" ou "502 Bad Gateway"
- V√©rifiez que Docker Compose est lanc√© : `docker compose ps`.
- Testez la sant√© : `curl http://localhost:8000/health`.
- V√©rifiez `.env` : Cl√© API upstream valide ?

### Probl√®me : "Invalid API key" (401)
- V√©rifiez `INTERNAL_API_KEY` dans `.env` et dans les headers d'OpenClaw.

### Probl√®me : "Daily budget exceeded" (402)
- R√©initialisez : `docker compose exec redis redis-cli DEL budget:default:2026-02-18`.
- Augmentez `DAILY_BUDGET_LIMIT` dans `.env`.

### Probl√®me : Streaming lent ou bloqu√©
- Assurez-vous que `stream: true` dans la requ√™te.
- Logs : `docker compose logs proxy` pour erreurs upstream.

### Logs Avanc√©s
- Voir les logs en temps r√©el : `docker compose logs -f proxy`.
- Erreurs Redis : `docker compose logs redis`.

Si rien ne marche, ouvrez une issue sur GitHub avec vos logs.

## 7. Fonctionnalit√©s Avanc√©es

- **Multi-utilisateurs** : √âtendez `verify_api_key()` pour mapper cl√©s √† users.
- **M√©triques** : Ajoutez Prometheus pour monitoring.
- **Scalabilit√©** : Utilisez plusieurs workers Uvicorn ou Kubernetes.
- **S√©curit√©** : Ajoutez HTTPS avec Caddy ou Traefik.

Pour plus de d√©tails, consultez le `README.md` du projet.

---

**Besoin d'aide ?** Posez des questions sur GitHub ou contactez l'auteur. Bonne int√©gration ! üöÄ
